---
title: "triGramsBlogs"
author: "Brian Perron"
date: "September 12, 2014"
output: html_document
---

Standard initialization


```{r}
rm(list=ls())
libs <- c("tm", "tau", "stringr", "reshape2", "stringi")
lapply(libs, require, character.only = TRUE)
```

Read the blog files and check the encoding
```{r}
blogs <- readLines("~/Git/capstoneCoursera/en_US/twitter.txt")
unique(stri_enc_mark(blogs))
```

Do general cleaning of blogs
```{r}
blogs <- tolower(blogs)
blogs <- gsub("/",   "", blogs)
blogs <- gsub("'", '', blogs)
blogs <- gsub("’", '', blogs)
blogs <- gsub("‘", '', blogs)
blogs <- gsub("′", '', blogs)
blogs <- gsub("”", '', blogs)
blogs <- gsub("“", '', blogs)
blogs <- gsub("@",   "", blogs)
blogs <- gsub("–", "", blogs)
blogs <- gsub("\\|", "", blogs)
blogs <- gsub("[!?,.]+", ".", blogs)
blogs <- gsub("…", "", blogs)
blogs <- gsub('[])(;:#%$^\\~{}[&+=@/"<>_]+', "", blogs)
blogs <- removeWords(blogs, stopwords("english"))
blogs <- stripWhitespace(blogs)
```

File is way too big -- let's start with taking a random subsample (XX).
```{r}
sampleLines <- c(1:length(blogs))
sampleSize <- sample(sampleLines, length(blogs)/2, replace = FALSE)
blogs <- blogs[sampleSize]
```


Create initial set of bi-grams and tri-grams
```{r}
trigrams <- textcnt(blogs, n = 3, method="string")
trigrams <- trigrams[order(trigrams, decreasing = TRUE)]
#print(bigrams[1:10])
print(trigrams[1:10])
```

Create bi-grams dataframe
```{r}
# Convert to data frame
trigrams.df <- as.data.frame(trigrams)

rm(trigrams) #General cleanup along the way

# Create a new variable containing bigrams (currently as row names)
trigrams.df$ng.1 <- rownames(trigrams.df)

# Split the new variable into individual tokens
trigrams.splitA.df <- colsplit(trigrams.df$ng.1, " ", c("ng1", "ng2"))
trigrams.splitB.df <- colsplit(trigrams.splitA.df$ng2, " ", c("ng2", "ng3"))

trigramsAB <- rep(NA, length(trigrams.splitA.df[,1])) 
for(i in 1:length(trigrams.splitA.df[,1])){
     trigramsAB[i] <- paste(trigrams.splitA.df[i,1], trigrams.splitB.df[i,1], sep = " ", collapse = " ")
     }

# Create a new data frame with the tokens and the bi-gram count
trigram.df.updated <- data.frame(trigrams.df, trigramsAB, trigrams.splitB.df$ng3)

names(trigram.df.updated)[4] <- "predicted" 

trigram.df <- trigram.df.updated
trigram.df <- trigram.df[complete.cases(trigram.df),]
```

Lots of stuff created.  Let's clean it all up and just keep the `trigram.df` object.  We can add more to the concatenating object if needed. 

```{r}
# Remove everything but X items
rm(list = setdiff(ls(), c("trigram.df")))
```

# Assume the user types in two words.  Let's take that entry and match it up with ng 3
```{r}
row.names(trigram.df) <- NULL 


tri.f <- function (x){
          lower.x <- tolower(x)
          #a <- match(lower.x, trigram.df[,"trigramsAB"]) # Match patterns - fix to exact word
          a <- grep(paste0(x, '$'), trigram.df[,"trigramsAB"]) 
          trigram.a <- trigram.df[a,] # Subset data
          trigram.a.ordered <- trigram.a[with(trigram.a, order(-trigrams)),]
          trigram.final.5 <- trigram.a.ordered[1:5,]
          trigram.final.5
          }
```


